#!/usr/bin/env python3
"""
accent_full_local.py

- Loads local SpeechBrain accent model (no HF symlinks).
- Robust audio loading + resampling.
- Robust label parsing from label_encoder.txt / accent_encoder.txt (classic "'label' => idx" format).
- Attempts multiple classify methods and prints friendly named results.
- Edit MODEL_DIR and INPUT_FILE below for your paths.
"""

import os, sys, traceback, shutil
from pathlib import Path

# ========== USER CONFIG ==========
# Edit these two paths as needed for your machine
MODEL_DIR = r"E:\new-voice\voice-checks\accent_app\pretrained_models\accent-id-commonaccent_ecapa"
INPUT_FILE = r"E:\new-voice\voice-checks\accent_app\test_audio\voice.wav"
# ==================================

# Force HF to avoid symlinks and use a project-local cache
os.environ["HF_HUB_DISABLE_SYMLINKS"] = "1"
os.environ["HF_HUB_DISABLE_SYMLINKS_WARNING"] = "1"
project_cache = os.path.join(os.path.dirname(__file__), ".hf_cache")
os.environ["HF_HOME"] = project_cache
os.environ["TRANSFORMERS_CACHE"] = project_cache
os.environ["HF_DATASETS_CACHE"] = project_cache

# Basic path checks
if not os.path.isdir(MODEL_DIR):
    print(f"‚ùå Model folder not found: {MODEL_DIR}")
    sys.exit(1)
if not os.path.exists(INPUT_FILE):
    print(f"‚ùå Input audio not found: {INPUT_FILE}")
    # If INPUT_FILE is directory, we can pick first wav later; but here require it
    sys.exit(1)

# Import heavy libs after env vars set
try:
    from speechbrain.inference import EncoderClassifier
except Exception:
    print("‚ùå Failed to import SpeechBrain. Ensure you're in the correct venv and 'speechbrain' is installed.")
    traceback.print_exc()
    sys.exit(1)

# -------------------------
# Label loader (robust)
# -------------------------
import re, json
def load_labels_from_model_dir(model_dir, classifier_obj=None):
    model_dir = Path(model_dir)
    candidates = [
        model_dir / "label_encoder.txt",
        model_dir / "accent_encoder.txt",
        model_dir / "data" / "label_encoder.txt",
        model_dir / "data" / "accent_encoder.txt",
    ]
    label_map = {}
    for p in candidates:
        if not p.exists():
            continue
        text = p.read_text(encoding="utf-8", errors="replace").strip()
        if not text:
            continue

        parsed_any = False
        for line in text.splitlines():
            line = line.strip()
            if not line:
                continue
            # "'label' => 0"
            m = re.match(r"""['"]([^'"]+)['"]\s*=>\s*([0-9]+)""", line)
            if m:
                lbl = m.group(1).strip()
                idx = int(m.group(2))
                label_map[idx] = lbl
                parsed_any = True
                continue
            # "label : index" or "label = index"
            m2 = re.match(r"""([^:=]+)[:=]\s*([0-9]+)""", line)
            if m2:
                lbl = m2.group(1).strip().strip("'\"")
                idx = int(m2.group(2))
                label_map[idx] = lbl
                parsed_any = True
                continue

        if parsed_any:
            break

        # fallbacks
        try:
            obj = json.loads(text)
            if isinstance(obj, list) and all(isinstance(x, str) for x in obj):
                return obj
        except Exception:
            pass

        if "," in text and len(text.split(",")) > 1:
            parts = [x.strip().strip("'\"") for x in text.split(",") if x.strip()]
            if parts:
                return parts

        lines = [ln.strip().strip("'\"") for ln in text.splitlines() if ln.strip()]
        if len(lines) > 1:
            return lines

    # convert label_map (index -> name) into ordered list
    if label_map:
        max_idx = max(label_map.keys())
        labels = [None] * (max_idx + 1)
        for idx, name in label_map.items():
            labels[idx] = name
        for i in range(len(labels)):
            if labels[i] is None:
                labels[i] = f"label_{i}"
        return labels

    # Try to extract from classifier object if provided
    if classifier_obj is not None:
        try:
            h = getattr(classifier_obj, "hparams", None)
            if h and "label_encoder" in h:
                val = h["label_encoder"]
                try:
                    return list(val)
                except Exception:
                    pass
        except Exception:
            pass

    return None

# -------------------------
# Robust audio classification helper
# -------------------------
def classify_audio_robust(classifier, filepath, target_sr=16000):
    import soundfile as sf
    import numpy as np
    import torch
    import librosa

    # 1) direct convenience wrapper
    try:
        print("Attempt 1: classifier.classify_file(...)")
        out = classifier.classify_file(filepath)
        print("-> classify_file succeeded")
        return out
    except Exception as e1:
        print("Attempt 1 failed:", repr(e1))

    # 2) load with soundfile (preferred), fallback to torchaudio
    data = None; sr = None
    try:
        print("Attempt 2: loading with soundfile...")
        data, sr = sf.read(filepath, always_2d=False)
        if hasattr(data, "ndim") and data.ndim > 1:
            data = data.mean(axis=1)
        data = data.astype(np.float32)
        print(f"Loaded: shape={data.shape}, sr={sr}")
    except Exception as e2:
        print("soundfile load failed:", repr(e2))
        try:
            import torchaudio
            print("Attempt 2b: loading with torchaudio...")
            waveform, sr = torchaudio.load(filepath)
            if waveform.ndim > 1:
                waveform = waveform.mean(dim=0)
            data = waveform.cpu().numpy().astype(np.float32)
            print(f"torchaudio loaded: shape={data.shape}, sr={sr}")
        except Exception as e2b:
            print("torchaudio load also failed:", repr(e2b))
            raise RuntimeError("Failed to load audio with soundfile and torchaudio") from e2b

    # 3) resample if needed
    if sr != target_sr:
        try:
            print(f"Resampling {sr} -> {target_sr} using librosa...")
            data = librosa.resample(data, orig_sr=sr, target_sr=target_sr)
            sr = target_sr
            print("Resample done. New length:", data.shape)
        except Exception as e_rs:
            print("librosa resample failed:", repr(e_rs))
            try:
                import torch, torchaudio
                tensor = torch.from_numpy(data).unsqueeze(0)
                resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)
                tensor_rs = resampler(tensor)
                data = tensor_rs.squeeze(0).cpu().numpy()
                sr = target_sr
                print("torchaudio resample succeeded.")
            except Exception as e_rs2:
                print("torchaudio resample failed too:", repr(e_rs2))

    # 4) try classify_batch and other call styles
    last_exc = None
    try_inputs = []
    import torch
    try_inputs.append(("numpy_1d", data))
    try_inputs.append(("numpy_list", [data]))
    try_inputs.append(("torch_1d", torch.from_numpy(data)))
    try_inputs.append(("torch_batched", torch.from_numpy(data).unsqueeze(0)))
    try_inputs.append(("pylist", data.tolist()))

    for name, inp in try_inputs:
        try:
            print(f"Attempt classify with input type: {name}")
            if hasattr(classifier, "classify_batch"):
                try:
                    out = classifier.classify_batch(inp)
                    print(f"-> classify_batch accepted input: {name}")
                    return out
                except Exception as e_cb:
                    print(f" classify_batch failed for {name}: {repr(e_cb)}")
                    last_exc = e_cb
            try:
                out = classifier.classify_file(inp)  # some wrappers accept arrays
                print(f"-> classify_file accepted non-path input: {name}")
                return out
            except Exception as e_cf:
                print(f" classify_file(non-path) failed for {name}: {repr(e_cf)}")
                last_exc = e_cf
        except Exception as e_any:
            print(f"Unexpected failure trying input {name}: {repr(e_any)}")
            last_exc = e_any

    print("All classify attempts failed. Raising last exception.")
    raise last_exc or RuntimeError("Unknown classification failure")

# -------------------------
# Load model (local)
# -------------------------
print("Loading model from local folder (no symlinks):", MODEL_DIR)
try:
    classifier = EncoderClassifier.from_hparams(source=MODEL_DIR, savedir=MODEL_DIR)
except Exception:
    print("‚ùå Model load failed. Traceback:")
    traceback.print_exc()
    sys.exit(1)

# -------------------------
# Load labels
# -------------------------
labels = load_labels_from_model_dir(MODEL_DIR, classifier_obj=classifier)
if labels:
    print("‚úÖ Labels loaded (index -> name):")
    for i, nm in enumerate(labels):
        print(f"  {i}: {nm}")
else:
    print("‚ö†Ô∏è Could not auto-load full label list. Predictions will show indices. Consider adding a proper label_encoder.txt")

# -------------------------
# Classify file (robust)
# -------------------------
print("\nClassifying:", INPUT_FILE)
try:
    out = classify_audio_robust(classifier, INPUT_FILE)
except Exception:
    print("‚ùå classify_file failed. Traceback:")
    traceback.print_exc()
    sys.exit(1)

# -------------------------
# Parse & display results
# -------------------------
import torch, numpy as np
print("\nüîß Debug: raw classifier output (for troubleshooting):")
print(out)

# normalize many possible output formats
logits = None
if isinstance(out, (tuple, list)) and len(out) >= 1:
    first = out[0]
    if hasattr(first, "squeeze"):
        logits = first.squeeze()
    else:
        try:
            logits = torch.tensor(first)
        except Exception:
            logits = None
else:
    if hasattr(out, "squeeze"):
        logits = out.squeeze()

if logits is None:
    print("‚ùå Could not interpret model output (no logits). Raw output printed above.")
    sys.exit(1)

if not isinstance(logits, torch.Tensor):
    logits = torch.tensor(logits)

probs = torch.nn.functional.softmax(logits, dim=-1).cpu().numpy()

if labels and len(labels) == len(probs):
    topk_idx = np.argsort(probs)[-5:][::-1]
    print("\nüîé Top predictions:")
    for i in topk_idx:
        print(f"  {labels[i]} ‚Äî {probs[i]*100:.2f}%")
    best = int(np.argmax(probs))
    print(f"\nüéØ Final Guess: {labels[best]} ‚Äî {probs[best]*100:.2f}%")
else:
    # fallback raw indices
    topk_idx = np.argsort(probs)[-10:][::-1]
    print("\nüîé Top raw predictions (index -> prob):")
    for i in topk_idx:
        print(f"  idx {i} -> {probs[i]*100:.6f}%")
    if labels:
        print("\n‚ö†Ô∏è Label count does not match probs length. Label sample (first 20):", labels[:20])
    else:
        print("\n‚ö†Ô∏è No labels available to map indices to names.")
